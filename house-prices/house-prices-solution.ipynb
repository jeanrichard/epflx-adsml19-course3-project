{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 3: Project - Part 2 - House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "This notebook is concerned with Part 2 - House prices.\n",
    "\n",
    "**Contents:**\n",
    "* [Imports](#step-0)\n",
    "* [Data cleaning](#step-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports<a name=\"step-0\"></a> ([top](#top))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library:\n",
    "import collections\n",
    "import json\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "# 3rd party:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning<a name=\"step-1\"></a> ([top](#top))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pathlib.Path.cwd() / 'house-prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by taking a look at the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Find and handle incorrect and missing values\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are told that the data set contains incorrect and missing values. Our plan is:\n",
    "\n",
    "* **Qualitative variables:** Make sur that they only take valid values. To that end, we have prepared a little JSON document that, for each nominal and ordinal variable, lists the valid values. (This document was generated by parsing the documentation. The code is in `qualitative_variables.py`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_null(series):\n",
    "    return series.isna().sum()\n",
    "\n",
    "\n",
    "def count_invalid(series, valid_values):\n",
    "    return (~series.isin(valid_values)).sum()\n",
    "    \n",
    "\n",
    "def check_quantitative(series):\n",
    "    print('null: {}'.format(count_null(series)))\n",
    "    print(series.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_fixes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the definitions of the qualitative variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qualitative_variables(path):\n",
    "    with open(path, 'r') as f:\n",
    "        definitions = json.load(f)\n",
    "        result = collections.OrderedDict()\n",
    "        for definition in definitions:\n",
    "            feature = definition['name']\n",
    "            attrs = {\n",
    "                'kind': definition['kind'],\n",
    "                'values': set(definition['values'])\n",
    "            }\n",
    "            result[feature] = attrs\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_vars = load_qualitative_variables('qualitative_variables.json')\n",
    "\n",
    "# As per the description of the task, we will not check 'PID':\n",
    "ql_vars.pop('PID')\n",
    "\n",
    "print(f'qualitative variables: {len(ql_vars)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st thing we notice when we try check the qualitative variables is that the names of some values differ between the data set and the documentation. *We decide to align the definitions to match the data set:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_var(cur_name, new_name):\n",
    "    attrs = ql_vars.pop(cur_name)\n",
    "    ql_vars[new_name] = attrs\n",
    "    \n",
    "    \n",
    "# 'Exterior 1' is 'Exterior 1st' in the data set:\n",
    "rename_var('Exterior 1', 'Exterior 1st')\n",
    "# 'Exterior 2' is 'Exterior 2nd' in the data set:\n",
    "rename_var('Exterior 2', 'Exterior 2nd')\n",
    "# 'BsmtFinType 2' is 'BsmtFin Type 2' in the data set:\n",
    "rename_var('BsmtFinType 2', 'BsmtFin Type 2')\n",
    "# 'HeatingQC' is 'Heating QC' in the data set:\n",
    "rename_var('HeatingQC', 'Heating QC')\n",
    "# 'KitchenQual' is 'Kitchen Qual' in the data set:\n",
    "rename_var('KitchenQual', 'Kitchen Qual')\n",
    "# 'FireplaceQu' is 'Fireplace Qu' in the data set:\n",
    "rename_var('FireplaceQu', 'Fireplace Qu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd thing we notice is that _NA_ in the documentation is represented by `np.nan` in the data set. *We decide to align the definitions to match the data set:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, attrs in ql_vars.items():\n",
    "    values = attrs['values']\n",
    "    if 'NA' in values:\n",
    "        print(f'fixing: {feature}')\n",
    "        values.remove('NA')\n",
    "        values.add(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the qualitative variables and output a data-frame with the number of null values and the number of invalid values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for feature, attrs in ql_vars.items():\n",
    "    series = df[feature]\n",
    "    null_count = count_null(series)\n",
    "    invalid_count = count_invalid(series, attrs['values'])\n",
    "    data.append((feature, attrs['kind'], null_count, invalid_count))\n",
    "df_ql = pd.DataFrame(data=data, columns=['feature', 'kind', 'null_count', 'invalid_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the qualitative variables that we need to investigage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ql[df_ql['invalid_count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS Zoning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the invalid values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'MS Zoning'\n",
    "values = ql_vars[feature]['values']\n",
    "invalid = df.loc[~df[feature].isin(values), feature]\n",
    "invalid.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a correction and register it for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(df, ql_vars):\n",
    "    feature = 'MS Zoning'\n",
    "    values = ql_vars[feature]['values']\n",
    "    # We only update invalid values:\n",
    "    invalid = df.loc[~df[feature].isin(values), feature]\n",
    "    corrected = invalid.map({'I (all)': 'I', 'C (all)': 'C', 'A (agr)': 'A'})\n",
    "    df.loc[corrected.index, feature] = corrected\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the correction:\n",
    "df = correct(df, ql_vars)\n",
    "assert count_invalid(df[feature], values) == 0, f\"variable: '{feature}' not properly corrected\"\n",
    "\n",
    "# Register the correction:\n",
    "ql_fixes.append(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhood (Nominal):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the invalid values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Neighborhood'\n",
    "values = ql_vars[feature]['values']\n",
    "invalid = df.loc[~df[feature].isin(values), feature]\n",
    "invalid.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the capitalization for `NWAmes`, we decide to align the definition to match the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Neighborhood'\n",
    "values = ql_vars[feature]['values']\n",
    "values.remove('Names')\n",
    "values.add('NAmes')\n",
    "\n",
    "assert count_invalid(df[feature], values) == 0, f\"variable: '{feature}' not properly corrected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
